{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMN9llJ4LMGRnFXwdCdgXJY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sannya-Wasim/Dice_AI_Course/blob/main/Assignment_02_Task_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Assignment 03**\n",
        "\n",
        "## Task 03\n",
        "\n",
        "In this task, the goal is to develop a Python program that enables users to select a query image from the \"query_images\" folder and retrieve the top N (N=4 in this case) similar images from the local directory named \"images_database\". To achieve this, the program will utilize the powerful TensorFlow library and its pre-trained **MobileNet Convolutional Neural Network (CNN) model** for feature extraction. Additionally, the program will employ the **Euclidean distance metric** for measuring the similarity between images. The program will also be designed to handle images in various formats such as JPG, PNG, and JPEG, thanks to the **Pillow library**.\n",
        "\n",
        "By implementing this solution, users will be able to find closely similar images in the database based on their query image, facilitating efficient image retrieval and analysis."
      ],
      "metadata": {
        "id": "asl6Lj2oqMOY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Downloading Dataset**"
      ],
      "metadata": {
        "id": "bn1Vw9lMqN7b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjWsAAs2qLf_",
        "outputId": "dfe5c426-daa8-405a-9d1f-47a2f53486b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.5.16)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.31.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.4)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ],
      "source": [
        "!pip install opendatasets --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "dataset_path = 'https://www.kaggle.com/datasets/swaroopkml/cifar10-pngs-in-folders'\n",
        "od.download(dataset_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SJr4To4qZdH",
        "outputId": "0366ed66-a6c3-42da-c168-61d8d85664a7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: sannyawasim\n",
            "Your Kaggle Key: ··········\n",
            "Downloading cifar10-pngs-in-folders.zip to ./cifar10-pngs-in-folders\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 140M/140M [00:01<00:00, 98.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data Pre-processing**"
      ],
      "metadata": {
        "id": "i9Busgy-re5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Flatten\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "O56OjhFureoS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining dimensions\n",
        "batch_size = 32\n",
        "img_width = 32\n",
        "img_height = 32"
      ],
      "metadata": {
        "id": "nCJ9-bQQrrVa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining path for train data\n",
        "train_data_path = '/content/cifar10-pngs-in-folders/cifar10/cifar10/images_database'\n",
        "test_data_path = '/content/cifar10-pngs-in-folders/cifar10/cifar10/query_images'"
      ],
      "metadata": {
        "id": "8a1JioGXr3xa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation splitting\n",
        "datagen = ImageDataGenerator(\n",
        "    preprocessing_function = preprocess_input,\n",
        "    validation_split = 0.2\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_data_path,\n",
        "    target_size = (img_width, img_height),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'categorical',\n",
        "    subset = 'training'\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    train_data_path,\n",
        "    target_size = (img_width, img_height),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'categorical',\n",
        "    subset = 'validation'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwoRiMgVsjMV",
        "outputId": "c0314b14-5a99-49e4-efa7-5114f11a95d9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 40000 images belonging to 10 classes.\n",
            "Found 10000 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# display the classes\n",
        "class_labels = train_generator.class_indices\n",
        "class_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEl8S_fBu2MK",
        "outputId": "28402575-15cd-43ee-e2dd-a13ab6dd0f93"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'airplane': 0,\n",
              " 'automobile': 1,\n",
              " 'bird': 2,\n",
              " 'cat': 3,\n",
              " 'deer': 4,\n",
              " 'dog': 5,\n",
              " 'frog': 6,\n",
              " 'horse': 7,\n",
              " 'ship': 8,\n",
              " 'truck': 9}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Fine Tuning VGG16 for Image Classification**"
      ],
      "metadata": {
        "id": "49-7gSC7vCFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://medium.com/@roshankg96/transfer-learning-and-fine-tuning-model-using-vgg-16-90b5401e1ebd\n",
        "num_classes = len(class_labels)\n",
        "\n",
        "# load the pre-trained model and removing the top layer --> https://www.tensorflow.org/api_docs/python/tf/keras/applications/vgg16/VGG16\n",
        "base_model = MobileNet(weights='imagenet', include_top = False, input_shape=(32, 32, 3))\n",
        "\n",
        "# The VGG16 model by default has an output shape of (None, 1000) before we add our custom classification layer.\n",
        "# Therefore add a Flatten layer before adding the GlobalAveragePooling2D layer to convert the 2D feature maps from the VGG16 model into a 1D tensor.\n",
        "\n",
        "# Freeze the layers\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)  # Global average pooling layer\n",
        "predictions = Dense(num_classes, activation='softmax')(x)  # Dense classification layer with softmax activation\n",
        "\n",
        "# Create the fine tuned model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJcFOdfTvIC5",
        "outputId": "d69c6a1e-0df7-4d58-a2c0-4c081c0512e6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
            "17225924/17225924 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nySeTivuzZD2",
        "outputId": "13d2c3b8-d3d4-4e86-dd3e-6d50c62e6637"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv1 (Conv2D)              (None, 16, 16, 32)        864       \n",
            "                                                                 \n",
            " conv1_bn (BatchNormalizati  (None, 16, 16, 32)        128       \n",
            " on)                                                             \n",
            "                                                                 \n",
            " conv1_relu (ReLU)           (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv_dw_1 (DepthwiseConv2D  (None, 16, 16, 32)        288       \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_1_bn (BatchNormali  (None, 16, 16, 32)        128       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_1_relu (ReLU)       (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv_pw_1 (Conv2D)          (None, 16, 16, 64)        2048      \n",
            "                                                                 \n",
            " conv_pw_1_bn (BatchNormali  (None, 16, 16, 64)        256       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_1_relu (ReLU)       (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv_pad_2 (ZeroPadding2D)  (None, 17, 17, 64)        0         \n",
            "                                                                 \n",
            " conv_dw_2 (DepthwiseConv2D  (None, 8, 8, 64)          576       \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_2_bn (BatchNormali  (None, 8, 8, 64)          256       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_2_relu (ReLU)       (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv_pw_2 (Conv2D)          (None, 8, 8, 128)         8192      \n",
            "                                                                 \n",
            " conv_pw_2_bn (BatchNormali  (None, 8, 8, 128)         512       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_2_relu (ReLU)       (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv_dw_3 (DepthwiseConv2D  (None, 8, 8, 128)         1152      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_3_bn (BatchNormali  (None, 8, 8, 128)         512       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_3_relu (ReLU)       (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv_pw_3 (Conv2D)          (None, 8, 8, 128)         16384     \n",
            "                                                                 \n",
            " conv_pw_3_bn (BatchNormali  (None, 8, 8, 128)         512       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_3_relu (ReLU)       (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv_pad_4 (ZeroPadding2D)  (None, 9, 9, 128)         0         \n",
            "                                                                 \n",
            " conv_dw_4 (DepthwiseConv2D  (None, 4, 4, 128)         1152      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_4_bn (BatchNormali  (None, 4, 4, 128)         512       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_4_relu (ReLU)       (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " conv_pw_4 (Conv2D)          (None, 4, 4, 256)         32768     \n",
            "                                                                 \n",
            " conv_pw_4_bn (BatchNormali  (None, 4, 4, 256)         1024      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_4_relu (ReLU)       (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " conv_dw_5 (DepthwiseConv2D  (None, 4, 4, 256)         2304      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_5_bn (BatchNormali  (None, 4, 4, 256)         1024      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_5_relu (ReLU)       (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " conv_pw_5 (Conv2D)          (None, 4, 4, 256)         65536     \n",
            "                                                                 \n",
            " conv_pw_5_bn (BatchNormali  (None, 4, 4, 256)         1024      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_5_relu (ReLU)       (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " conv_pad_6 (ZeroPadding2D)  (None, 5, 5, 256)         0         \n",
            "                                                                 \n",
            " conv_dw_6 (DepthwiseConv2D  (None, 2, 2, 256)         2304      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_6_bn (BatchNormali  (None, 2, 2, 256)         1024      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_6_relu (ReLU)       (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " conv_pw_6 (Conv2D)          (None, 2, 2, 512)         131072    \n",
            "                                                                 \n",
            " conv_pw_6_bn (BatchNormali  (None, 2, 2, 512)         2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_6_relu (ReLU)       (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " conv_dw_7 (DepthwiseConv2D  (None, 2, 2, 512)         4608      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_7_bn (BatchNormali  (None, 2, 2, 512)         2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_7_relu (ReLU)       (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " conv_pw_7 (Conv2D)          (None, 2, 2, 512)         262144    \n",
            "                                                                 \n",
            " conv_pw_7_bn (BatchNormali  (None, 2, 2, 512)         2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_7_relu (ReLU)       (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " conv_dw_8 (DepthwiseConv2D  (None, 2, 2, 512)         4608      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_8_bn (BatchNormali  (None, 2, 2, 512)         2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_8_relu (ReLU)       (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " conv_pw_8 (Conv2D)          (None, 2, 2, 512)         262144    \n",
            "                                                                 \n",
            " conv_pw_8_bn (BatchNormali  (None, 2, 2, 512)         2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_8_relu (ReLU)       (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " conv_dw_9 (DepthwiseConv2D  (None, 2, 2, 512)         4608      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_9_bn (BatchNormali  (None, 2, 2, 512)         2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_9_relu (ReLU)       (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " conv_pw_9 (Conv2D)          (None, 2, 2, 512)         262144    \n",
            "                                                                 \n",
            " conv_pw_9_bn (BatchNormali  (None, 2, 2, 512)         2048      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_9_relu (ReLU)       (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " conv_dw_10 (DepthwiseConv2  (None, 2, 2, 512)         4608      \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv_dw_10_bn (BatchNormal  (None, 2, 2, 512)         2048      \n",
            " ization)                                                        \n",
            "                                                                 \n",
            " conv_dw_10_relu (ReLU)      (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " conv_pw_10 (Conv2D)         (None, 2, 2, 512)         262144    \n",
            "                                                                 \n",
            " conv_pw_10_bn (BatchNormal  (None, 2, 2, 512)         2048      \n",
            " ization)                                                        \n",
            "                                                                 \n",
            " conv_pw_10_relu (ReLU)      (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " conv_dw_11 (DepthwiseConv2  (None, 2, 2, 512)         4608      \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv_dw_11_bn (BatchNormal  (None, 2, 2, 512)         2048      \n",
            " ization)                                                        \n",
            "                                                                 \n",
            " conv_dw_11_relu (ReLU)      (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " conv_pw_11 (Conv2D)         (None, 2, 2, 512)         262144    \n",
            "                                                                 \n",
            " conv_pw_11_bn (BatchNormal  (None, 2, 2, 512)         2048      \n",
            " ization)                                                        \n",
            "                                                                 \n",
            " conv_pw_11_relu (ReLU)      (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " conv_pad_12 (ZeroPadding2D  (None, 3, 3, 512)         0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_12 (DepthwiseConv2  (None, 1, 1, 512)         4608      \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv_dw_12_bn (BatchNormal  (None, 1, 1, 512)         2048      \n",
            " ization)                                                        \n",
            "                                                                 \n",
            " conv_dw_12_relu (ReLU)      (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " conv_pw_12 (Conv2D)         (None, 1, 1, 1024)        524288    \n",
            "                                                                 \n",
            " conv_pw_12_bn (BatchNormal  (None, 1, 1, 1024)        4096      \n",
            " ization)                                                        \n",
            "                                                                 \n",
            " conv_pw_12_relu (ReLU)      (None, 1, 1, 1024)        0         \n",
            "                                                                 \n",
            " conv_dw_13 (DepthwiseConv2  (None, 1, 1, 1024)        9216      \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv_dw_13_bn (BatchNormal  (None, 1, 1, 1024)        4096      \n",
            " ization)                                                        \n",
            "                                                                 \n",
            " conv_dw_13_relu (ReLU)      (None, 1, 1, 1024)        0         \n",
            "                                                                 \n",
            " conv_pw_13 (Conv2D)         (None, 1, 1, 1024)        1048576   \n",
            "                                                                 \n",
            " conv_pw_13_bn (BatchNormal  (None, 1, 1, 1024)        4096      \n",
            " ization)                                                        \n",
            "                                                                 \n",
            " conv_pw_13_relu (ReLU)      (None, 1, 1, 1024)        0         \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 1024)              0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3239114 (12.36 MB)\n",
            "Trainable params: 10250 (40.04 KB)\n",
            "Non-trainable params: 3228864 (12.32 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "wJL6b3N-zuJq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    validation_data = validation_generator,\n",
        "    epochs=10\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcwFpsjn0Br3",
        "outputId": "b0263431-e1a3-432b-d9af-814af000ea9a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 38s 22ms/step - loss: 2.2682 - accuracy: 0.1450 - val_loss: 2.2491 - val_accuracy: 0.1651\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 27s 22ms/step - loss: 2.2386 - accuracy: 0.1681 - val_loss: 2.2372 - val_accuracy: 0.1671\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 2.2283 - accuracy: 0.1724 - val_loss: 2.2317 - val_accuracy: 0.1727\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 24s 20ms/step - loss: 2.2226 - accuracy: 0.1739 - val_loss: 2.2297 - val_accuracy: 0.1713\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 2.2189 - accuracy: 0.1756 - val_loss: 2.2276 - val_accuracy: 0.1685\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 24s 19ms/step - loss: 2.2164 - accuracy: 0.1752 - val_loss: 2.2269 - val_accuracy: 0.1722\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 24s 20ms/step - loss: 2.2142 - accuracy: 0.1775 - val_loss: 2.2261 - val_accuracy: 0.1700\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 2.2127 - accuracy: 0.1760 - val_loss: 2.2257 - val_accuracy: 0.1684\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 2.2112 - accuracy: 0.1782 - val_loss: 2.2259 - val_accuracy: 0.1719\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 25s 20ms/step - loss: 2.2100 - accuracy: 0.1780 - val_loss: 2.2257 - val_accuracy: 0.1701\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7cc2e3f1a260>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('cifar_MobileNet.h5', save_format='h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e-jLVQrCN2L",
        "outputId": "fe1173e8-586c-4847-c65d-197a2cc18fd6"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Implementing Similarity Index**\n",
        "\n",
        "To find the similarity between the two images we are going to use '**Euclidean Distance**' with the following approach :\n",
        "\n",
        "1. Read the image files as an array.\n",
        "2. Since the image files are colored there are 3 channels for RGB values.  We are going to flatten them such that each image is a single 1-D array.\n",
        "3. Once we have our image files as an array we are going to generate a histogram for each image where for each index 0 – 255 we are going the count the occurrence of that pixel value in the image.\n",
        "4. Once we have our histograms we are going to use the L2-Norm or Euclidean Distance to find the difference the two histograms.\n",
        "5. Based on the distance between the histogram of our test image and the reference images we can find the image our test image is most similar to.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jxE31H84krNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing neceassary libraries\n",
        "from PIL import Image   # Image to read the image in terms of numerical values\n",
        "from collections import Counter     # Counter to count the number of times each pixel value (0-255) occurs in the images.\n",
        "import numpy as np      # Numpy for storing the image as Numpy array"
      ],
      "metadata": {
        "id": "pK71dH7Hne5x"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ref_img_1 = Image.open('/content/cifar10-pngs-in-folders/cifar10/cifar10/images_database/deer/0090.png')\n",
        "ref_img_2 = Image.open('/content/cifar10-pngs-in-folders/cifar10/cifar10/images_database/horse/0034.png')\n",
        "\n",
        "array_1 = np.asarray(ref_img_1)\n",
        "array_2 = np.asarray(ref_img_2)\n",
        "\n",
        "print(np.shape(ref_img_1))\n",
        "print(np.shape(ref_img_2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGpH4GWln8Xs",
        "outputId": "535bdf9c-75c0-4864-9ed0-699786803ceb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 32, 3)\n",
            "(32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten this 3D array into a 1D array\n",
        "flat_array_1 = array_1.flatten()\n",
        "flat_array_2 = array_2.flatten()"
      ],
      "metadata": {
        "id": "-n6ALwW4sEpv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating the count-histogram Vector\n",
        "RH1 = Counter(flat_array_1)\n",
        "RH2 = Counter(flat_array_2)\n",
        "# returns a dictionary where the key corresponds to the pixel value and the value of the key is the number of times that pixel is present in the image."
      ],
      "metadata": {
        "id": "d2vvifA6tDvV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One limitation of Euclidean distance is that it requires all the vectors to be normalized i.e both the vectors need to be of the same dimensions. To ensure that our histogram vector is normalized we are going to use a for loop from 0-255 and generate our histogram with the value of the key if the key is present in the image else we append a 0."
      ],
      "metadata": {
        "id": "FDXM0XJwtcVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining Histogram\n",
        "H1 = []\n",
        "for i in range(256):\n",
        "  if i in RH1.keys():\n",
        "    H1.append(RH1[i])\n",
        "  else:\n",
        "    H1.append(0)\n",
        "\n",
        "# generates a vector of size (256, ) where each index corresponds to the pixel value and the value corresponds to the count of the pixel in that image."
      ],
      "metadata": {
        "id": "kmaGrS93tdLM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining Histogram\n",
        "H2 = []\n",
        "for i in range(256):\n",
        "  if i in RH2.keys():\n",
        "    H2.append(RH2[i])\n",
        "  else:\n",
        "    H2.append(0)\n",
        "\n",
        "# generates a vector of size (256, ) where each index corresponds to the pixel value and the value corresponds to the count of the pixel in that image."
      ],
      "metadata": {
        "id": "qz05sWEtduJ_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Euclidean Distance Function**"
      ],
      "metadata": {
        "id": "7H3jw89bvBm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function takes in two histograms and returns the euclidean distance between them.\n",
        "\n",
        "def L2Norm(H1, H2):\n",
        "  distance = 0\n",
        "  for i in range(len(H1)):\n",
        "    distance += np.square(H1[i]-H2[i])\n",
        "  return np.sqrt(distance)"
      ],
      "metadata": {
        "id": "747AwiUWvGYn"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Defining our Test Image**\n",
        "Our test image is going to be that of a cat from the query_images. We will find the distance between reference image 1 and test image and the same for reference image 2. The smallest distance means the greater the similarity between the two pictures"
      ],
      "metadata": {
        "id": "5qJIEprNcDnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_image = Image.open('/content/cifar10-pngs-in-folders/cifar10/cifar10/query_images/horse/0048.png')\n",
        "test_array = np.asarray(test_image)\n",
        "flatten_array_test = test_array.flatten()\n",
        "\n",
        "# Generating count histogram counter\n",
        "TH1 = Counter(flatten_array_test)\n",
        "\n",
        "# Defining histogram\n",
        "HT = []\n",
        "for i in range(256):\n",
        "  if i in RH1.keys():\n",
        "    HT.append(TH1[i])\n",
        "  else:\n",
        "    HT.append(0)"
      ],
      "metadata": {
        "id": "tAE8XLtib-3w"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dist_test_ref_1 = L2Norm(H1, HT)\n",
        "print(\"The distance between Reference Image 1 (Deer) and Test Image (Horse) is {}\".format(dist_test_ref_1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcRw6c-_a9oI",
        "outputId": "418635ac-3e39-4c58-e40a-b1821981f417"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The distance between Reference Image 1 (Deer) and Test Image (Horse) is 193.9690696992693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dist_test_ref_2 = L2Norm(H2, HT)\n",
        "print(\"The distance between Reference Image 2 (Horse) and Test Image (Horse) is {}\".format(dist_test_ref_2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsYdM5n5dkgD",
        "outputId": "685f1350-1598-4d6f-d03c-1c4d7f88456b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The distance between Reference Image 2 (Horse) and Test Image (Horse) is 178.48249213858483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Implementing the Image Retrieval System**\n",
        "\n",
        "https://towardsdatascience.com/build-an-image-search-engine-using-python-ad181e76441b"
      ],
      "metadata": {
        "id": "DAyoU5QppwYg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finding Top 'N' similar images**"
      ],
      "metadata": {
        "id": "fLU2t1L5vXmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from collections import Counter, defaultdict\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def calculate_euclidean_distance(query_array, database_folder):\n",
        "    query_histogram = Counter(query_array)\n",
        "    similar_images = []\n",
        "\n",
        "    for category in os.listdir(database_folder):\n",
        "        category_folder = os.path.join(database_folder, category)\n",
        "        for image_name in os.listdir(category_folder):\n",
        "            image_path = os.path.join(category_folder, image_name)\n",
        "            database_image = Image.open(image_path)\n",
        "            database_array = np.asarray(database_image).flatten()\n",
        "            database_histogram = Counter(database_array)\n",
        "\n",
        "            # Initialize default dictionaries for query and database histograms\n",
        "            query_histogram = defaultdict(int)\n",
        "            database_histogram = defaultdict(int)\n",
        "\n",
        "            # Generate histograms for query and database images\n",
        "            for pixel_value in query_array:\n",
        "                query_histogram[pixel_value] += 1\n",
        "\n",
        "            for pixel_value in database_array:\n",
        "                database_histogram[pixel_value] += 1\n",
        "\n",
        "            # Make sure histograms have the same set of keys (pixel values)\n",
        "            all_keys = set(query_histogram.keys()).union(set(database_histogram.keys()))\n",
        "\n",
        "            # Fill in missing keys with 0 counts\n",
        "            for key in all_keys:\n",
        "                query_histogram[key] = query_histogram.get(key, 0)\n",
        "                database_histogram[key] = database_histogram.get(key, 0)\n",
        "\n",
        "            # Calculate Euclidean distance\n",
        "            distance = np.linalg.norm(np.array(list(query_histogram.values())) - np.array(list(database_histogram.values())))\n",
        "            similar_images.append((image_path, distance))\n",
        "\n",
        "    return similar_images\n",
        "\n",
        "# Read and prepare the query image\n",
        "query_image_path = '/content/cifar10-pngs-in-folders/cifar10/cifar10/query_images/cat/0075.png'\n",
        "query_image = Image.open(query_image_path)\n",
        "query_array = np.asarray(query_image).flatten()\n",
        "\n",
        "# Prepare the database images\n",
        "database_folder = '/content/cifar10-pngs-in-folders/cifar10/cifar10/images_database'\n",
        "\n",
        "# Find the top N similar images\n",
        "top_n = 4\n",
        "similar_images = calculate_euclidean_distance(query_array, database_folder)\n",
        "similar_images.sort(key=lambda x: x[1])\n",
        "top_similar_images = similar_images[:top_n]\n",
        "\n",
        "# Print the paths of top similar images and their distances\n",
        "for image_path, distance in top_similar_images:\n",
        "    print(f\"Image Path: {image_path}, Distance: {distance}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUgbec7qqCmL",
        "outputId": "a899acc6-9cc2-441c-87d0-bc54f31cb3dc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image Path: /content/cifar10-pngs-in-folders/cifar10/cifar10/images_database/horse/1783.png, Distance: 142.59032225224823\n",
            "Image Path: /content/cifar10-pngs-in-folders/cifar10/cifar10/images_database/horse/0027.png, Distance: 143.52003344481216\n",
            "Image Path: /content/cifar10-pngs-in-folders/cifar10/cifar10/images_database/cat/0725.png, Distance: 144.3606594609487\n",
            "Image Path: /content/cifar10-pngs-in-folders/cifar10/cifar10/images_database/frog/1714.png, Distance: 146.0\n"
          ]
        }
      ]
    }
  ]
}